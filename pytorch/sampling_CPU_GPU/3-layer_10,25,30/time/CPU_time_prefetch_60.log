Training in cpu mode.
Loading data
Training...
epoch  0
use_uva  False

Epoch 00000 | Loss 8.349975 
epoch  1
use_uva  False

Epoch 00001 | Loss 7.385678 
epoch  2
use_uva  False

Epoch 00002 | Loss 6.564473 
epoch  3
use_uva  False

Epoch 00003 | Loss 5.894269 
epoch  4
use_uva  False

Epoch 00004 | Loss 5.333843 
epoch  5
use_uva  False

Epoch 00005 | Loss 4.959919 
epoch  6
use_uva  False

Epoch 00006 | Loss 4.656486 
epoch  7
use_uva  False

Epoch 00007 | Loss 4.449570 
epoch  8
use_uva  False

Epoch 00008 | Loss 4.258811 
epoch  9
use_uva  False

Epoch 00009 | Loss 4.088852 
epoch  10
use_uva  False
train time  7.018399953842163
dataloader_time  5.025603771209717
feature and label time  3.409385681152344e-05
model time  0.9744658470153809
loss, backward, opt step  time  1.0182185173034668

Epoch 00010 | Loss 3.895316 
epoch  11
use_uva  False
train time  6.870121717453003
dataloader_time  5.066142320632935
feature and label time  4.1961669921875e-05
model time  0.7910971641540527
loss, backward, opt step  time  1.0127513408660889

Epoch 00011 | Loss 3.716100 
epoch  12
use_uva  False
train time  6.733981609344482
dataloader_time  4.868402719497681
feature and label time  3.647804260253906e-05
model time  0.7852201461791992
loss, backward, opt step  time  1.080247163772583

Epoch 00012 | Loss 3.561728 
epoch  13
use_uva  False
train time  7.590837001800537
dataloader_time  5.529625654220581
feature and label time  4.6253204345703125e-05
model time  0.8959543704986572
loss, backward, opt step  time  1.1650140285491943

Epoch 00013 | Loss 3.405838 
epoch  14
use_uva  False
train time  7.362892389297485
dataloader_time  5.473590135574341
feature and label time  4.076957702636719e-05
model time  0.8752429485321045
loss, backward, opt step  time  1.0139272212982178

Epoch 00014 | Loss 3.273607 
epoch  15
use_uva  False
train time  7.1832239627838135
dataloader_time  5.201276540756226
feature and label time  4.1484832763671875e-05
model time  0.8226706981658936
loss, backward, opt step  time  1.1591556072235107

Epoch 00015 | Loss 3.124008 
epoch  16
use_uva  False
train time  7.2538981437683105
dataloader_time  5.3375654220581055
feature and label time  2.9325485229492188e-05
model time  0.906559944152832
loss, backward, opt step  time  1.00966477394104

Epoch 00016 | Loss 3.036768 
epoch  17
use_uva  False
train time  6.554574012756348
dataloader_time  4.736418962478638
feature and label time  4.076957702636719e-05
model time  0.8272194862365723
loss, backward, opt step  time  0.9907996654510498

Epoch 00017 | Loss 2.941401 
epoch  18
use_uva  False
train time  7.3044068813323975
dataloader_time  5.167280197143555
feature and label time  7.05718994140625e-05
model time  1.077019453048706
loss, backward, opt step  time  1.059960126876831

Epoch 00018 | Loss 2.855143 
epoch  19
use_uva  False
train time  6.474501371383667
dataloader_time  4.658365249633789
feature and label time  3.933906555175781e-05
model time  0.7980899810791016
loss, backward, opt step  time  1.0179121494293213

Epoch 00019 | Loss 2.784546 
epoch  20
use_uva  False
train time  7.142533302307129
dataloader_time  5.325502872467041
feature and label time  3.886222839355469e-05
model time  0.830376386642456
loss, backward, opt step  time  0.9865241050720215

Epoch 00020 | Loss 2.704032 
epoch  21
use_uva  False
train time  6.630561351776123
dataloader_time  4.781252384185791
feature and label time  3.7670135498046875e-05
model time  0.7977931499481201
loss, backward, opt step  time  1.0514006614685059

Epoch 00021 | Loss 2.625527 
epoch  22
use_uva  False
train time  6.613373279571533
dataloader_time  4.773523569107056
feature and label time  3.6716461181640625e-05
model time  0.7880966663360596
loss, backward, opt step  time  1.0516395568847656

Epoch 00022 | Loss 2.550681 
epoch  23
use_uva  False
train time  6.663344383239746
dataloader_time  4.810450553894043
feature and label time  4.00543212890625e-05
model time  0.8532218933105469
loss, backward, opt step  time  0.9995546340942383

Epoch 00023 | Loss 2.473497 
epoch  24
use_uva  False
train time  6.555200815200806
dataloader_time  4.751254558563232
feature and label time  4.291534423828125e-05
model time  0.7848808765411377
loss, backward, opt step  time  1.0188896656036377

Epoch 00024 | Loss 2.409108 
epoch  25
use_uva  False
train time  6.497084617614746
dataloader_time  4.714686393737793
feature and label time  3.910064697265625e-05
model time  0.7647533416748047
loss, backward, opt step  time  1.0175204277038574

Epoch 00025 | Loss 2.351164 
epoch  26
use_uva  False
train time  7.034915447235107
dataloader_time  5.2090442180633545
feature and label time  3.695487976074219e-05
model time  0.7480728626251221
loss, backward, opt step  time  1.0776848793029785

Epoch 00026 | Loss 2.289281 
epoch  27
use_uva  False
train time  7.025340557098389
dataloader_time  5.138391494750977
feature and label time  3.695487976074219e-05
model time  0.78865647315979
loss, backward, opt step  time  1.0981788635253906

Epoch 00027 | Loss 2.224068 
epoch  28
use_uva  False
train time  6.628497123718262
dataloader_time  4.774889945983887
feature and label time  3.62396240234375e-05
model time  0.8222987651824951
loss, backward, opt step  time  1.0311977863311768

Epoch 00028 | Loss 2.183444 
epoch  29
use_uva  False
train time  6.97895073890686
dataloader_time  5.240681409835815
feature and label time  4.100799560546875e-05
model time  0.7536003589630127
loss, backward, opt step  time  0.9845502376556396

Epoch 00029 | Loss 2.131161 
epoch  30
use_uva  False
train time  6.840219497680664
dataloader_time  5.097135782241821
feature and label time  3.6716461181640625e-05
model time  0.7620055675506592
loss, backward, opt step  time  0.9809670448303223

Epoch 00030 | Loss 2.087551 
epoch  31
use_uva  False
train time  7.105509519577026
dataloader_time  5.2051379680633545
feature and label time  3.910064697265625e-05
model time  0.7990610599517822
loss, backward, opt step  time  1.1011929512023926

Epoch 00031 | Loss 2.041490 
epoch  32
use_uva  False
train time  6.829633951187134
dataloader_time  4.963275671005249
feature and label time  3.719329833984375e-05
model time  0.8400592803955078
loss, backward, opt step  time  1.0261847972869873

Epoch 00032 | Loss 2.006424 
epoch  33
use_uva  False
train time  6.981107473373413
dataloader_time  5.119389057159424
feature and label time  4.315376281738281e-05
model time  0.8323087692260742
loss, backward, opt step  time  1.0292866230010986

Epoch 00033 | Loss 1.975081 
epoch  34
use_uva  False
train time  6.901652097702026
dataloader_time  4.974207162857056
feature and label time  4.029273986816406e-05
model time  0.839827299118042
loss, backward, opt step  time  1.0874979496002197

Epoch 00034 | Loss 1.927282 
epoch  35
use_uva  False
train time  7.235511541366577
dataloader_time  5.489635944366455
feature and label time  4.220008850097656e-05
model time  0.7503907680511475
loss, backward, opt step  time  0.9953620433807373

Epoch 00035 | Loss 1.889383 
epoch  36
use_uva  False
train time  6.865702152252197
dataloader_time  5.038867950439453
feature and label time  4.100799560546875e-05
model time  0.8228864669799805
loss, backward, opt step  time  1.0038278102874756

Epoch 00036 | Loss 1.851146 
epoch  37
use_uva  False
train time  6.538182973861694
dataloader_time  4.685633420944214
feature and label time  4.1484832763671875e-05
model time  0.7658560276031494
loss, backward, opt step  time  1.0865740776062012

Epoch 00037 | Loss 1.821242 
epoch  38
use_uva  False
train time  7.258492469787598
dataloader_time  5.086560964584351
feature and label time  4.00543212890625e-05
model time  1.0276985168457031
loss, backward, opt step  time  1.1440865993499756

Epoch 00038 | Loss 1.787460 
epoch  39
use_uva  False
train time  7.487279415130615
dataloader_time  5.4822797775268555
feature and label time  4.9591064453125e-05
model time  0.8776936531066895
loss, backward, opt step  time  1.1271631717681885

Epoch 00039 | Loss 1.752012 
epoch  40
use_uva  False
train time  6.523065805435181
dataloader_time  4.676975727081299
feature and label time  4.029273986816406e-05
model time  0.7877864837646484
loss, backward, opt step  time  1.0581750869750977

Epoch 00040 | Loss 1.718577 
epoch  41
use_uva  False
train time  6.566989421844482
dataloader_time  4.72601842880249
feature and label time  4.1484832763671875e-05
model time  0.826488733291626
loss, backward, opt step  time  1.014352560043335

Epoch 00041 | Loss 1.695108 
epoch  42
use_uva  False
train time  6.5613977909088135
dataloader_time  4.6979944705963135
feature and label time  3.838539123535156e-05
model time  0.8120424747467041
loss, backward, opt step  time  1.0512220859527588

Epoch 00042 | Loss 1.664807 
epoch  43
use_uva  False
train time  6.7193284034729
dataloader_time  4.868977069854736
feature and label time  3.886222839355469e-05
model time  0.8065965175628662
loss, backward, opt step  time  1.0436272621154785

Epoch 00043 | Loss 1.637861 
epoch  44
use_uva  False
train time  7.223601818084717
dataloader_time  5.401949882507324
feature and label time  4.0531158447265625e-05
model time  0.7756123542785645
loss, backward, opt step  time  1.0459105968475342

Epoch 00044 | Loss 1.610040 
epoch  45
use_uva  False
train time  7.214003801345825
dataloader_time  5.310960292816162
feature and label time  4.1484832763671875e-05
model time  0.7815783023834229
loss, backward, opt step  time  1.121333360671997

Epoch 00045 | Loss 1.582391 
epoch  46
use_uva  False
train time  6.692465543746948
dataloader_time  4.767927646636963
feature and label time  3.981590270996094e-05
model time  0.873009443283081
loss, backward, opt step  time  1.051398515701294

Epoch 00046 | Loss 1.565232 
epoch  47
use_uva  False
train time  7.100379467010498
dataloader_time  5.245640993118286
feature and label time  3.981590270996094e-05
model time  0.7914540767669678
loss, backward, opt step  time  1.0631451606750488

Epoch 00047 | Loss 1.540740 
epoch  48
use_uva  False
train time  6.914032936096191
dataloader_time  5.064717769622803
feature and label time  4.267692565917969e-05
model time  0.7712838649749756
loss, backward, opt step  time  1.0778441429138184

Epoch 00048 | Loss 1.509144 
epoch  49
use_uva  False
train time  6.65104603767395
dataloader_time  4.816612958908081
feature and label time  4.076957702636719e-05
model time  0.762606143951416
loss, backward, opt step  time  1.0716955661773682

Epoch 00049 | Loss 1.494071 
epoch  50
use_uva  False
train time  6.768209934234619
dataloader_time  4.947283983230591
feature and label time  3.981590270996094e-05
model time  0.7838387489318848
loss, backward, opt step  time  1.0369560718536377

Epoch 00050 | Loss 1.467180 
epoch  51
use_uva  False
train time  6.5469725131988525
dataloader_time  4.730191469192505
feature and label time  3.9577484130859375e-05
model time  0.7749576568603516
loss, backward, opt step  time  1.041696548461914

Epoch 00051 | Loss 1.448825 
epoch  52
use_uva  False
train time  6.770565986633301
dataloader_time  4.929715394973755
feature and label time  3.933906555175781e-05
model time  0.7840902805328369
loss, backward, opt step  time  1.056619644165039

Epoch 00052 | Loss 1.423876 
epoch  53
use_uva  False
train time  6.672354698181152
dataloader_time  4.871748447418213
feature and label time  4.100799560546875e-05
model time  0.7999131679534912
loss, backward, opt step  time  1.000561237335205

Epoch 00053 | Loss 1.411744 
epoch  54
use_uva  False
train time  6.705337285995483
dataloader_time  4.894869089126587
feature and label time  3.886222839355469e-05
model time  0.7761001586914062
loss, backward, opt step  time  1.034238338470459

Epoch 00054 | Loss 1.389858 
epoch  55
use_uva  False
train time  6.58988094329834
dataloader_time  4.701724290847778
feature and label time  3.981590270996094e-05
model time  0.822455883026123
loss, backward, opt step  time  1.0655605792999268

Epoch 00055 | Loss 1.368178 
epoch  56
use_uva  False
train time  6.58605170249939
dataloader_time  4.692279577255249
feature and label time  3.123283386230469e-05
model time  0.9036781787872314
loss, backward, opt step  time  0.989995002746582

Epoch 00056 | Loss 1.359815 
epoch  57
use_uva  False
train time  6.397836923599243
dataloader_time  4.598050355911255
feature and label time  3.24249267578125e-05
model time  0.780327320098877
loss, backward, opt step  time  1.0193588733673096

Epoch 00057 | Loss 1.339718 
epoch  58
use_uva  False
train time  6.525686264038086
dataloader_time  4.558634281158447
feature and label time  4.4345855712890625e-05
model time  0.8691971302032471
loss, backward, opt step  time  1.0977404117584229

Epoch 00058 | Loss 1.322317 
epoch  59
use_uva  False
train time  6.7051684856414795
dataloader_time  4.678348779678345
feature and label time  3.600120544433594e-05
model time  0.855487585067749
loss, backward, opt step  time  1.1712281703948975

Epoch 00059 | Loss 1.302174 

mean training time/epoch 6.851886110305786
mean dataloader time/epoch 4.9781338596344
mean feature label time/epoch 4.009723663330078e-05
mean modeling time/epoch 0.822831654548645
mean left time/epoch 1.0507918739318847
