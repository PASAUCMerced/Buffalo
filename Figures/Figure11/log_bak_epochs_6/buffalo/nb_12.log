main start at this time 1734655633.6913102
-----------------------------------------before load data 
 Nvidia-smi: 0.3560791015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.3560791015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

epoch  0
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13065862655639648
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.00035691261291503906
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.010761260986328125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13124299049377441
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.4594836235046387
self.buckets_partition() spend  sec:  0.14202141761779785
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 5.2053937911987305
----------------------------------------after train
 Nvidia-smi: 22.95068359375 GB
    Memory Allocated: 0.5931186676025391  GigaBytes
Max Memory Allocated: 21.224058151245117  GigaBytes

epoch  1
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13268208503723145
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0003795623779296875
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.010407447814941406
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13320112228393555
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.438260555267334
self.buckets_partition() spend  sec:  0.14362621307373047
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 4.887924671173096
----------------------------------------after train
 Nvidia-smi: 22.97802734375 GB
    Memory Allocated: 0.5925149917602539  GigaBytes
Max Memory Allocated: 21.224058151245117  GigaBytes

epoch  2
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13379955291748047
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0006053447723388672
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.010876178741455078
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13455414772033691
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.495948076248169
self.buckets_partition() spend  sec:  0.14556646347045898
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 4.5881829261779785
----------------------------------------after train
 Nvidia-smi: 22.97802734375 GB
    Memory Allocated: 0.5924191474914551  GigaBytes
Max Memory Allocated: 21.224058151245117  GigaBytes

epoch  3
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13378024101257324
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0006394386291503906
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.012691020965576172
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13457679748535156
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.459074020385742
self.buckets_partition() spend  sec:  0.14729976654052734
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 4.299322128295898
----------------------------------------after train
 Nvidia-smi: 22.97802734375 GB
    Memory Allocated: 0.5923662185668945  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch  4
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13475728034973145
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0006415843963623047
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.011611700057983398
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13559246063232422
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.4349794387817383
self.buckets_partition() spend  sec:  0.14722371101379395
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 4.042543888092041
----------------------------------------after train
 Nvidia-smi: 23.00146484375 GB
    Memory Allocated: 0.5940918922424316  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch  5
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13302111625671387
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0006692409515380859
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.010785579681396484
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13392066955566406
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.428591728210449
self.buckets_partition() spend  sec:  0.14472603797912598
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 3.805602788925171
----------------------------------------after train
 Nvidia-smi: 23.35888671875 GB
    Memory Allocated: 0.5962615013122559  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch_time_list  [23.44345235824585, 21.011994123458862, 20.021104097366333, 19.308614253997803, 19.479257345199585, 18.893582344055176]

loading_time list   [0.5608978271484375, 0.5957207679748535, 0.5196270942687988, 0.5500288009643555, 0.3073000907897949, 0.36816906929016113]

 data loader gen time  [14.303362369537354, 14.344963312149048, 13.782855987548828, 13.321724653244019, 13.444706201553345, 13.059608697891235]
	---backpack schedule time  [2.5313780307769775, 2.5029215812683105, 2.577389717102051, 2.526923656463623, 2.5031447410583496, 2.4898903369903564]
	---connection_check_time_list  [6.985472679138184, 7.096470355987549, 6.58864951133728, 6.264422178268433, 6.489748001098633, 6.157689571380615]
	---block_gen_time_list  [4.119389772415161, 4.059117317199707, 3.9421439170837402, 3.901111125946045, 3.8303964138031006, 3.781045436859131]
training time  [8.578697204589844, 6.067445755004883, 5.7138121128082275, 5.431696891784668, 5.722482204437256, 5.4606757164001465]
---feature block loading time  [3.092329502105713, 3.467045307159424, 3.4107306003570557, 3.1301400661468506, 3.124443292617798, 3.133556842803955]


below are the average time (sec)
End to end time   19.18641984462738
	---Buffalo scheduling  2.496517539024353
	---Connection check   6.323718786239624
	---Block construction   3.8057209253311157
    ---Data loading  3.4667346477508545
    ---Training time on GPU  2.2796898682912192
