main start at this time 1735269777.0446742
-----------------------------------------before load data 
 Nvidia-smi: 0.3560791015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.3560791015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

epoch  0
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13329267501831055
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0003917217254638672
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014188528060913086
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13394975662231445
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.468562126159668
self.buckets_partition() spend  sec:  0.14815497398376465
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 5.204830169677734
----------------------------------------after train
 Nvidia-smi: 22.93115234375 GB
    Memory Allocated: 0.5949568748474121  GigaBytes
Max Memory Allocated: 21.225086212158203  GigaBytes

epoch  1
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.1347670555114746
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0008153915405273438
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.012064218521118164
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13576674461364746
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.4316277503967285
self.buckets_partition() spend  sec:  0.14785099029541016
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 4.892384052276611
----------------------------------------after train
 Nvidia-smi: 22.93505859375 GB
    Memory Allocated: 0.5935359001159668  GigaBytes
Max Memory Allocated: 21.225086212158203  GigaBytes

epoch  2
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.1349782943725586
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0007328987121582031
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.011794805526733398
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13599824905395508
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.47668719291687
self.buckets_partition() spend  sec:  0.14791297912597656
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 4.5932440757751465
----------------------------------------after train
 Nvidia-smi: 22.93505859375 GB
    Memory Allocated: 0.5919623374938965  GigaBytes
Max Memory Allocated: 21.225086212158203  GigaBytes

epoch  3
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13705015182495117
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0011630058288574219
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013475656509399414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13839197158813477
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.470142364501953
self.buckets_partition() spend  sec:  0.15189766883850098
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 4.306056022644043
----------------------------------------after train
 Nvidia-smi: 22.95068359375 GB
    Memory Allocated: 0.593468189239502  GigaBytes
Max Memory Allocated: 21.225086212158203  GigaBytes

epoch  4
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13464093208312988
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.000911712646484375
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.011124849319458008
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13571715354919434
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.4804675579071045
self.buckets_partition() spend  sec:  0.1468651294708252
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 4.042313575744629
----------------------------------------after train
 Nvidia-smi: 23.02294921875 GB
    Memory Allocated: 0.5907487869262695  GigaBytes
Max Memory Allocated: 21.27092981338501  GigaBytes

epoch  5
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.4462575912475586
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0010037422180175781
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.010804176330566406
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.447662353515625
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.737307548522949
self.buckets_partition() spend  sec:  0.4584963321685791
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 3.800767660140991
----------------------------------------after train
 Nvidia-smi: 23.02294921875 GB
    Memory Allocated: 0.5929446220397949  GigaBytes
Max Memory Allocated: 21.27092981338501  GigaBytes

epoch_time_list  [24.682523727416992, 21.048619031906128, 19.575634717941284, 20.18677520751953, 20.004148483276367, 19.004588842391968]

loading_time list   [0.54960036277771, 0.6322894096374512, 0.50687575340271, 0.5133180618286133, 0.5413572788238525, 0.45359277725219727]

 data loader gen time  [17.23483943939209, 14.919890642166138, 14.001417636871338, 14.177795171737671, 14.015579223632812, 13.472336053848267]
	---backpack schedule time  [2.5419161319732666, 2.5202138423919678, 2.5421056747436523, 2.5367636680603027, 2.5472264289855957, 2.8051791191101074]
	---connection_check_time_list  [9.760011434555054, 7.61278223991394, 6.8508827686309814, 7.154876232147217, 6.8668529987335205, 6.295708179473877]
	---block_gen_time_list  [4.2340147495269775, 4.090188264846802, 3.929338216781616, 3.818800687789917, 3.9309446811676025, 3.725095510482788]
training time  [6.897204637527466, 5.490678071975708, 5.060865879058838, 5.48859977722168, 5.439764022827148, 5.0716469287872314]
---feature block loading time  [2.987514019012451, 2.7899203300476074, 2.6847329139709473, 2.780444622039795, 2.7395200729370117, 2.6929190158843994]


below are the average time (sec)
End to end time   19.504368662834167
	---Buffalo scheduling  2.6762027740478516
	---Connection check   6.581280589103699
	---Block construction   3.8280200958251953
	---Data loading  3.2136945724487305
	---Training time on GPU  2.471699078877767
